{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bert Visualize\n",
    "> Visualize masked language modeling transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp bert_visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForMaskedLM,AutoTokenizer\n",
    "from forgebox.imports import *\n",
    "from forgebox.config import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9d984caf2724389b7adad2c0f835b1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "489a32ddaed342f8910255156b47bbf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForMaskedLM were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['cls.predictions.decoder.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "415afb21020b49d4b6f4950299d14da2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForMaskedLM.from_pretrained(\"bert-base-uncased\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\",use_fast=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A piece of sample text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"I must not [MASK].\n",
    "Fear is the mind-killer.\n",
    "Fear is the little [MASK] that brings total obliteration.\n",
    "I will face my fear.\n",
    "I will permit it to pass over me and through me.\n",
    "And when it has gone past I will turn the inner [MASK] to see its path.\n",
    "Where the fear has gone there will be nothing.\n",
    "Only I will remain.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLMVisualizer:\n",
    "    def __init__(self,model,tokenizer):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "    @classmethod\n",
    "    def from_pretrained(cls,\n",
    "                        tag:\"str, like how you use from_pretrained from transformers\"\n",
    "                       ):\n",
    "        obj = cls(\n",
    "                model = AutoModelForMaskedLM.from_pretrained(tag),\n",
    "                tokenizer = AutoTokenizer.from_pretrained(tag,use_fast=True),\n",
    "        )\n",
    "        return obj\n",
    "        \n",
    "    def tok(self,text:str,)->[\n",
    "            torch.FloatTensor,\n",
    "            torch.BoolTensor,\n",
    "            list,\n",
    "        ]:\n",
    "        \"\"\"\n",
    "        A specific way of tokenizing.\n",
    "            with pytorch tensor as input\n",
    "            with mask tensor specifying where's the [MASK] token\n",
    "            with offset mapping marking the positions \n",
    "                in format of list in list\n",
    "        \"\"\"\n",
    "        tokenized = self.tokenizer(\n",
    "            text,\n",
    "            return_tensors = \"pt\",\n",
    "            return_offsets_mapping=True\n",
    "        )\n",
    "        x = tokenized['input_ids']\n",
    "        offset_mapping = tokenized['offset_mapping']\n",
    "        mask = x==self.tokenizer.mask_token_id\n",
    "        return x,mask,offset_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForMaskedLM were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['cls.predictions.decoder.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "vis = MLMVisualizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def li(x,)->np.array:\n",
    "    if torch.is_tensor(x):\n",
    "        x=x.cpu().numpy()\n",
    "    return x.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_logits(\n",
    "        vis,\n",
    "        y_pred,\n",
    "        mask) -> Config:\n",
    "    logits = softmax(y_pred[mask])\n",
    "    pred_idx = logits.argmax(-1)\n",
    "    return Config(\n",
    "        logits=logits,\n",
    "        pred_idx=pred_idx,\n",
    "        pred_tokens = tokenizer.convert_ids_to_tokens(pred_idx)\n",
    "    )\n",
    "\n",
    "\n",
    "MLMVisualizer.infer_logits = infer_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_text(\n",
    "        vis,\n",
    "        text,\n",
    "           )->Config:\n",
    "    with torch.no_grad():\n",
    "        x,mask,mapper=vis.tok(text)\n",
    "        y_pred,attention = vis.model(x,output_attentions=True)\n",
    "        infered = vis.infer_logits(y_pred,mask)\n",
    "    return Config(\n",
    "        text = text,\n",
    "        x = li(x),\n",
    "        mask = li(mask),\n",
    "        mapper = li(mapper),\n",
    "#         y_pred = li(y_pred),\n",
    "#         logits = li(infered.logits),\n",
    "        pred_idx=li(infered.pred_idx),\n",
    "        pred_tokens =infered.pred_tokens,\n",
    "        attention = list(map(li,attention)),\n",
    "    )\n",
    "MLMVisualizer.predict_text = predict_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jinja2 import Template\n",
    "from forgebox.html import DOM\n",
    "import json\n",
    "from uuid import uuid4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(vis,\n",
    "              text):\n",
    "    result = vis.predict_text(text)\n",
    "    vis.visualize_result(result)\n",
    "\n",
    "\n",
    "def visualize_result(vis, result: Config):\n",
    "    with open('mlm_visual.html', 'r') as f:\n",
    "        template = Template(f.read())\n",
    "    with open('mlm_visual.js', 'r') as f:\n",
    "        js = f.read()\n",
    "    text = result.text\n",
    "    delattr(result, 'text')\n",
    "    output_id = str(uuid4())\n",
    "    page = template.render(data=json.dumps(result),\n",
    "                           text=text,\n",
    "                           output_id=output_id,\n",
    "                           mlm_visual_js=js)\n",
    "    DOM(page, \"div\",)()\n",
    "\n",
    "\n",
    "MLMVisualizer.visualize = visualize\n",
    "MLMVisualizer.visualize_result = visualize_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 789 ms, sys: 23.7 ms, total: 813 ms\n",
      "Wall time: 231 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = predict_text(vis,text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "vis.visualize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
