{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiprocessing Helper\n",
    "> Things to smooth up the multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp multiproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from typing import List, Dict, Callable, Any, Tuple\n",
    "import random\n",
    "from multiprocessing import Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate Process Magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class VipaClass:\n",
    "    \"\"\"\n",
    "    From meditation word Vipassana\n",
    "    Where creating a magic function\n",
    "    you can run a cell without holding the entire notebook\n",
    "    ```ipython\n",
    "    %%vipas\n",
    "    ...do things\n",
    "    ```\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.procs = []\n",
    "\n",
    "    def vipas(self, line, cell):\n",
    "        \"\"\"\n",
    "        run a cell magic function, that will not hold the process\n",
    "        \"\"\"\n",
    "        ishell = get_ipython()\n",
    "        proc = Process(target=ishell.run_cell, args = (cell,), daemon=True)\n",
    "        proc.start()\n",
    "        self.procs.append(proc)\n",
    "            \n",
    "try:\n",
    "    ishell = get_ipython()\n",
    "    from IPython.core import magic\n",
    "    vipa_class = VipaClass()\n",
    "    magic.register_cell_magic(vipa_class.vipas)\n",
    "    vipas = vipa_class.vipas\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read single file line by line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class SingleFileLiner:\n",
    "    \"\"\"\n",
    "    Text data reading line by line for multiprocessing\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, file_path: Path, total: int = None):\n",
    "        \"\"\"\n",
    "        filepath: Path,\n",
    "            path to a textual file\n",
    "        total: int\n",
    "            if you set total to an integer, we'll have a fixed length interation object\n",
    "            if you set total to None, we'll read the file till it's over\n",
    "        \"\"\"\n",
    "        self.file_path = Path(file_path)\n",
    "        global SingleFileLiner_fp\n",
    "        SingleFileLiner_fp = open(file_path, \"r\")\n",
    "        global text_line_num\n",
    "        text_line_num = 0\n",
    "        self.total = total\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"SingleFileLiner:\\t{self.file_path}\"\n",
    "\n",
    "    def __next__(self) -> str:\n",
    "        global SingleFileLiner_fp\n",
    "        line = SingleFileLiner_fp.readline()\n",
    "        global text_line_num\n",
    "        text_line_num += 1\n",
    "        if line == \"\":\n",
    "            if self.total is None:\n",
    "                raise StopIteration(f\"SingleFileLiner file read finish\")\n",
    "            logging.warning(f\"looping on {self.file_path}\")\n",
    "\n",
    "            self.restart()\n",
    "        return line.strip()\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.total is not None:\n",
    "            return self.total\n",
    "        else:\n",
    "            raise RuntimeError(f\"You have to set total for len(self)\")\n",
    "\n",
    "    def __iter__(self) -> str:\n",
    "        if self.total is None:\n",
    "            while True:\n",
    "                try:\n",
    "                    yield next(self)\n",
    "                except StopIteration:\n",
    "                    # end the file reading\n",
    "                    break\n",
    "        else:\n",
    "            for i in range(self.total):\n",
    "                yield next(self)\n",
    "\n",
    "    def restart(self) -> None:\n",
    "        \"\"\"resetart file reader\"\"\"\n",
    "        global SingleFileLiner_fp\n",
    "        SingleFileLiner_fp.close()\n",
    "        SingleFileLiner_fp = open(self.file_path, \"r\")\n",
    "\n",
    "    def split_train_test(\n",
    "            self,\n",
    "            val_ratio: float = 0.1,\n",
    "            remove_original: bool = False,\n",
    "            logging_interval: int = 1000000) -> Tuple[Path]:\n",
    "        \"\"\"\n",
    "        Split the text file into train and test\n",
    "        :param val_ratio:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        suffix = self.file_path.suffix\n",
    "\n",
    "        train_file_path = self.file_path.parent / \\\n",
    "            f\"{self.file_path.stem}_train{suffix}\"\n",
    "        valid_file_path = self.file_path.parent / \\\n",
    "            f\"{self.file_path.stem}_valid{suffix}\"\n",
    "\n",
    "        # delete the file if exists\n",
    "        if remove_original:\n",
    "            train_file_path.unlink()\n",
    "            valid_file_path.unlink()\n",
    "\n",
    "        # read and write by line\n",
    "        with open(self.file_path, \"r\") as f, open(\n",
    "            train_file_path, \"w\") as f_train, open(\n",
    "            valid_file_path, \"w\") as f_valid:\n",
    "            for i, line in enumerate(f):\n",
    "                if i % 1000000 == 0:\n",
    "                    logging.info(f\"{i}\\tlines processed\")\n",
    "                if random.random() < val_ratio:\n",
    "                    f_valid.write(line)\n",
    "                else:\n",
    "                    f_train.write(line)\n",
    "        return train_file_path, valid_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfl = SingleFileLiner(\"../README.md\")\n",
    "from joblib import Parallel, delayed\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_line(x):\n",
    "#     sleep(1)\n",
    "    return x\n",
    "\n",
    "res = Parallel(backend=\"multiprocessing\", n_jobs=6)(delayed(get_line)(i) for i in sfl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read dataframe row by row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class DataFrameRowling:\n",
    "    \"\"\"\n",
    "    Read dataframe row by row\n",
    "    \"\"\"\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.restart()\n",
    "        \n",
    "    def restart(self):\n",
    "        global DataFrameRowling_df\n",
    "        DataFrameRowling_df = self.df\n",
    "        global DataFrameRowling_ct\n",
    "        DataFrameRowling_ct = 0\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"DataFrameRowling:\\t{len(self)} Rows\"\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for i in range(len(self)):\n",
    "            yield next(self)\n",
    "            \n",
    "    def __getitem__(self, idx):\n",
    "        global DataFrameRowling_df\n",
    "        return DataFrameRowling_df[list(DataFrameRowling_df.index)[idx]]\n",
    "            \n",
    "    def __next__(self):\n",
    "        global DataFrameRowling_df\n",
    "        global DataFrameRowling_ct\n",
    "        row = DataFrameRowling_df.loc[list(DataFrameRowling_df.index)[DataFrameRowling_ct]]\n",
    "        DataFrameRowling_ct+=1\n",
    "        return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({\"col1\":list(range(100))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = Parallel(backend=\"multiprocessing\", n_jobs=6)(delayed(get_line)(i) for i in DataFrameRowling(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "col1    5\n",
       "Name: 5, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
